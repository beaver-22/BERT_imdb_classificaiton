# ------------------------------
# ëª¨ë¸ ê´€ë ¨ ì„¤ì •
# ------------------------------
model:
  pretrained_name: answerdotai/ModernBERT-base   # ë˜ëŠ” ModernBERT-base
  num_labels: 2                        # IMDBëŠ” ê¸Â·ë¶€ì • ë‘ í´ë˜ìŠ¤
  dropout: 0.1                         # ë¶„ë¥˜ í—¤ë“œ dropout í™•ë¥ 


# ------------------------------
# ë°ì´í„° ê²½ë¡œ ë° ì „ì²˜ë¦¬
# ------------------------------
data:
  pretrained_name: answerdotai/ModernBERT-base   # ë˜ëŠ” ModernBERT-base
  dataset_name: stanfordnlp/imdb       # ğŸ¤— Hub ì´ë¦„
  max_len: 128                         # í† í° ìµœëŒ€ ê¸¸ì´ ëŒ€ëµ 85.3%ê°€ ì»¤ë²„ë¨
  split_ratio: [0.8, 0.1, 0.1]       # train/val/test ë¹„ìœ¨
  seed: 42                             # ë°ì´í„° ì…”í”Œ ì¬í˜„ì„±


# ------------------------------
# í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ------------------------------
train:
  batch_size: 64                        # BERTëŠ” ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆê°€ ì¼ë°˜ì 
  num_epochs: 5
  lr: 5e-5
  optimizer: adam                     # ê·œì¹™ìƒ Adam ì‚¬ìš©
  scheduler: constant
  grad_clip: 1.0                       # ì„ íƒ: gradient clipping


# ------------------------------
# Validation ë° í‰ê°€ ì„¤ì •
# ------------------------------
validation:
  eval_strategy: epoch                 # ë§¤ epochë§ˆë‹¤ í‰ê°€
  eval_steps: null                     # epoch ê¸°ì¤€ì´ë¯€ë¡œ null
  metric_for_best_model: eval_accuracy # ìµœê³  ëª¨ë¸ ì„ íƒ ê¸°ì¤€
  greater_is_better: true              # accuracyëŠ” í´ìˆ˜ë¡ ì¢‹ìŒ
  load_best_model_at_end: true         # í•™ìŠµ ì™„ë£Œ í›„ ìµœê³  ëª¨ë¸ ë¡œë“œ
  
  # í‰ê°€ ì¤‘ ì‚¬ìš©í•  ë©”íŠ¸ë¦­ë“¤
  metrics:
    - accuracy
    - f1
    - precision 
    - recall


# ------------------------------
# ì²´í¬í¬ì¸íŠ¸ & ëª¨ë¸ ì €ì¥
# ------------------------------
checkpointing:
  save_strategy: epoch                 # ë§¤ epochë§ˆë‹¤ ì €ì¥
  save_steps: null                     # epoch ê¸°ì¤€ì´ë¯€ë¡œ null
  save_total_limit: 3                  # ìµœëŒ€ 3ê°œ ì²´í¬í¬ì¸íŠ¸ë§Œ ìœ ì§€
  save_only_best: false               # ëª¨ë“  epoch ì €ì¥ (ë‚˜ì¤‘ì— ì„ íƒ ê°€ëŠ¥)
  
  # ì €ì¥í•  íŒŒì¼ë“¤
  save_components:
    - model                            # ëª¨ë¸ ê°€ì¤‘ì¹˜
    - optimizer                        # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
    - scheduler                        # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ
    - tokenizer                        # í† í¬ë‚˜ì´ì €
    - training_args                    # í•™ìŠµ ì„¤ì •
  
  # íŒŒì¼ ì´ë¦„ í˜•ì‹
  output_dir: checkpoints/imdb-modernbert
  checkpoint_name_format: "checkpoint-epoch-{epoch:02d}-acc-{eval_accuracy:.4f}"


# ------------------------------
# ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
# ------------------------------
log:
  # WandB ì„¤ì •
  wandb_project: imdb-sentiment
  wandb_entity: beaver22-seoul-national-university    # í™˜ê²½ë³€ìˆ˜ë¡œ ë®ì–´ì“°ê¸° ê¶Œì¥
  wandb_name: Mordenbert-{timestamp}    # ì‹¤í—˜ ì´ë¦„
  
  # ë¡œê¹… ë¹ˆë„
  log_strategy: steps                  # ìŠ¤í… ë‹¨ìœ„ ë¡œê¹…
  logging_steps: 100                   # 100 ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸
  
  # ì €ì¥í•  ë¡œê·¸ ì •ë³´
  log_metrics:
    - train_loss
    - eval_loss  
    - eval_accuracy
    - eval_precision
    - eval_recall
    - eval_f1
    - learning_rate
    - epoch
    - step
  
  # ë¡œê·¸ íŒŒì¼ ì €ì¥
  log_file: logs/training.log
  log_level: INFO


# ------------------------------
# ëª¨ë¸ ì €ì¥ ì„¸ë¶€ ì„¤ì •
# ------------------------------
model_saving:
  # Best model ì €ì¥
  save_best_model: true
  best_model_dir: models/best/
  best_model_metric: eval_accuracy
  
  # Final model ì €ì¥  
  save_final_model: true
  final_model_dir: models/final/
  
  # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸ ìë™ ì •ë¦¬
  auto_cleanup: true
  keep_best_n: 2                       # ìƒìœ„ 2ê°œ ëª¨ë¸ë§Œ ìœ ì§€


# ------------------------------
# í•˜ë“œì›¨ì–´ ë° ê¸°íƒ€
# ------------------------------
runtime:
  device: cuda                         # cpu | cuda
  fp16: true                           # mixed-precision í•™ìŠµ ì—¬ë¶€
  dataloader_num_workers: 4            # ë°ì´í„° ë¡œë”© í”„ë¡œì„¸ìŠ¤ ìˆ˜
  pin_memory: true                     # GPU ë©”ëª¨ë¦¬ ìµœì í™”
  
  # ì¬í˜„ì„± ì„¤ì •
  seed: 42
  deterministic: true
